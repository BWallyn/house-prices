# Here you can define all your data sets by using simple YAML syntax.
#
# Documentation for this file format can be found in "The Data Catalog"
# Link: https://docs.kedro.org/en/stable/data/data_catalog.html

train_raw_data:
  type: pandas.CSVDataSet
  filepath: data/01_raw/train.csv
  layer: raw

test_raw_data:
  type: pandas.CSVDataSet
  filepath: data/01_raw/test.csv
  layer: raw

split_train:
  type: pandas.ParquetDataSet
  filepath: data/03_primary/train_split.parquet
  layer: primary

split_valid:
  type: pandas.ParquetDataSet
  filepath: data/03_primary/valid_split.parquet
  layer: primary

processed_train:
  type: pandas.ParquetDataSet
  filepath: data/04_features/train_feat.parquet
  layer: features

processed_valid:
  type: pandas.ParquetDataSet
  filepath: data/04_features/valid_feat.parquet
  layer: features

train_data:
  type: pandas.ParquetDataSet
  filepath: data/05_model_input/df_train.parquet
  layer: model_input

valid_data:
  type: pandas.ParquetDataSet
  filepath: data/05_model_input/df_valid.parquet
  layer: model_input

test_data:
  type: pandas.ParquetDataSet
  filepath: data/05_model_input/df_test.parquet
  layer: model_input

ml_model:
  type: pickle.PickleDataSet
  filepath: data/06_models/ml_model.pkl
  backend: pickle
  layer: models

pred_train:
  type: pandas.CSVDataSet
  filepath: data/07_model_output/pred_train.csv
  layer: model_output

pred_test:
  type: pandas.CSVDataSet
  filepath: data/07_model_output/pred_test.csv
  layer: model_output